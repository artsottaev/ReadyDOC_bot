import os
from aiogram import Bot, Dispatcher, F, types
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.types import Message
from aiogram.enums.parse_mode import ParseMode
from aiogram.fsm.storage.memory import MemoryStorage
from openai import AsyncOpenAI
from dotenv import load_dotenv

load_dotenv()

BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

bot = Bot(token=BOT_TOKEN, parse_mode=ParseMode.HTML)
dp = Dispatcher(storage=MemoryStorage())
openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)

class DocGenState(StatesGroup):
    waiting_for_initial_input = State()
    waiting_for_special_terms = State()

@dp.message(F.text)
async def handle_initial_description(message: Message, state: FSMContext):
    await state.update_data(initial_text=message.text)

    # –ü–æ–¥—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ, —á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–∂–µ –Ω–∞–ø–∏—Å–∞–ª –∫–∞–∫ —Å—É—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞
    prompt = f"–°–æ—Å—Ç–∞–≤—å —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –¥–æ–∫—É–º–µ–Ω—Ç: {message.text}"
    await message.answer("–ì–µ–Ω–µ—Ä–∏—Ä—É—é –¥–æ–∫—É–º–µ–Ω—Ç... üß†")

    response = await openai_client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "–¢—ã –æ–ø—ã—Ç–Ω—ã–π —é—Ä–∏—Å—Ç, —Å–æ–∑–¥–∞—é—â–∏–π —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ —Ä–æ—Å—Å–∏–π—Å–∫–æ–º—É –ø—Ä–∞–≤—É."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3,
        max_tokens=3000
    )

    document_text = response.choices[0].message.content.strip()
    await state.update_data(document_text=document_text)

    await message.answer("–í–æ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç:\n\n" + document_text)
    await message.answer("–ï—Å—Ç—å –ª–∏ –æ—Å–æ–±—ã–µ —É—Å–ª–æ–≤–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –≤ –¥–æ–∫—É–º–µ–Ω—Ç? –ù–∞–ø–∏—à–∏ –∏—Ö, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ. –ò–ª–∏ –Ω–∞–ø–∏—à–∏ '–Ω–µ—Ç'.")
    await state.set_state(DocGenState.waiting_for_special_terms)

@dp.message(DocGenState.waiting_for_special_terms)
async def handle_special_terms(message: Message, state: FSMContext):
    data = await state.get_data()
    base_text = data["document_text"]

    if message.text.strip().lower() == "–Ω–µ—Ç":
        await message.answer("–î–æ–∫—É–º–µ–Ω—Ç –∑–∞–≤–µ—Ä—à—ë–Ω ‚úÖ")
        await state.clear()
        return

    # –î–æ–±–∞–≤–∏–º —É—Å–ª–æ–≤–∏—è –∫–∞–∫ post-processing —á–µ—Ä–µ–∑ GPT
    post_prompt = (
        "–í–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç, —Å–æ–∑–¥–∞–Ω–Ω—ã–π —é—Ä–∏—Å—Ç–æ–º. –î–æ–±–∞–≤—å –≤ –Ω–µ–≥–æ —Å–ª–µ–¥—É—é—â–∏–µ –æ—Å–æ–±—ã–µ —É—Å–ª–æ–≤–∏—è: "
        f"{message.text}\n\n–î–æ–∫—É–º–µ–Ω—Ç:\n{base_text}"
    )

    response = await openai_client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "–¢—ã —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π —Ä–µ–¥–∞–∫—Ç–æ—Ä. –î–æ–±–∞–≤—å —É—Å–ª–æ–≤–∏—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ, —Å–æ–±–ª—é–¥–∞—è —Å—Ç–∏–ª—å –¥–æ–∫—É–º–µ–Ω—Ç–∞."},
            {"role": "user", "content": post_prompt}
        ],
        temperature=0.3,
        max_tokens=3000
    )

    final_doc = response.choices[0].message.content.strip()
    await message.answer("–î–æ–∫—É–º–µ–Ω—Ç —Å –æ—Å–æ–±—ã–º–∏ —É—Å–ª–æ–≤–∏—è–º–∏:\n\n" + final_doc)
    await message.answer("‚úÖ –ì–æ—Ç–æ–≤–æ")
    await state.clear()

if __name__ == "__main__":
    import asyncio
    asyncio.run(dp.start_polling(bot))
