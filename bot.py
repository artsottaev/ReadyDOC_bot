import os
import logging
import asyncio
from aiogram import Bot, Dispatcher, F, types
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.fsm.storage.redis import RedisStorage
from aiogram.enums.parse_mode import ParseMode
from aiogram.types import Message, FSInputFile
from openai import AsyncOpenAI
from dotenv import load_dotenv
from docx import Document

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()
BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
REDIS_HOST = os.getenv("REDIS_HOST", "localhost")
REDIS_PORT = int(os.getenv("REDIS_PORT", 6379))

# –í–∞–ª–∏–¥–∞—Ü–∏—è
if not BOT_TOKEN or not OPENAI_API_KEY:
    raise ValueError("BOT_TOKEN –∏ OPENAI_API_KEY –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã!")

# –õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
bot = Bot(token=BOT_TOKEN, parse_mode=ParseMode.HTML)
storage = RedisStorage.from_url(f"redis://{REDIS_HOST}:{REDIS_PORT}/0")
dp = Dispatcher(storage=storage)
openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)


# FSM
class DocGenState(StatesGroup):
    waiting_for_initial_input = State()
    waiting_for_special_terms = State()


# GPT –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
async def generate_gpt_response(system_prompt: str, user_prompt: str) -> str:
    try:
        response = await openai_client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            max_tokens=3000
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ OpenAI: {e}")
        return "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."


# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ .docx
def save_docx(text: str, filename: str) -> str:
    doc = Document()
    for para in text.split("\n"):
        doc.add_paragraph(para)
    filepath = os.path.join("/tmp", filename)
    doc.save(filepath)
    return filepath


# /start
@dp.message(F.text == "/start")
async def cmd_start(message: Message, state: FSMContext):
    await state.clear()
    await message.answer(
        "üëã –ü—Ä–∏–≤–µ—Ç! –Ø –ø–æ–º–æ–≥—É —Å–æ—Å—Ç–∞–≤–∏—Ç—å —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –¥–æ–∫—É–º–µ–Ω—Ç.\n\n"
        "–ü—Ä–æ—Å—Ç–æ –æ–ø–∏—à–∏, –∫–∞–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç —Ç–µ–±–µ –Ω—É–∂–µ–Ω. –ù–∞–ø—Ä–∏–º–µ—Ä:\n"
        "<i>–ù—É–∂–µ–Ω –¥–æ–≥–æ–≤–æ—Ä –∞—Ä–µ–Ω–¥—ã –æ—Ñ–∏—Å–∞ –º–µ–∂–¥—É –ò–ü –∏ –û–û–û –Ω–∞ –≥–æ–¥</i>"
    )
    await state.set_state(DocGenState.waiting_for_initial_input)


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–ø–∏—Å–∞–Ω–∏—è
@dp.message(DocGenState.waiting_for_initial_input)
async def handle_description(message: Message, state: FSMContext):
    if len(message.text) > 3000:
        await message.answer("‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç. –£–∫–æ—Ä–æ—Ç–∏, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞.")
        return

    await state.update_data(initial_text=message.text)
    prompt = f"–°–æ—Å—Ç–∞–≤—å —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ —Ä–æ—Å—Å–∏–π—Å–∫–æ–º—É –ø—Ä–∞–≤—É. –í–æ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\n\n\"{message.text}\""
    await message.answer("üß† –ì–µ–Ω–µ—Ä–∏—Ä—É—é —á–µ—Ä–Ω–æ–≤–∏–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞...")

    document = await generate_gpt_response(
        "–¢—ã –æ–ø—ã—Ç–Ω—ã–π —é—Ä–∏—Å—Ç. –°–æ—Å—Ç–∞–≤—å —é—Ä–∏–¥–∏—á–µ—Å–∫–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç.",
        prompt
    )

    await state.update_data(document_text=document)
    filename = f"draft_{message.from_user.id}.docx"
    path = save_docx(document, filename)
    await message.answer("üìÑ –í–æ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç:")
    await message.answer_document(FSInputFile(path))
    await message.answer("–•–æ—á–µ—à—å –¥–æ–±–∞–≤–∏—Ç—å –æ—Å–æ–±—ã–µ —É—Å–ª–æ–≤–∏—è? –ù–∞–ø–∏—à–∏ –∏—Ö –∏–ª–∏ –Ω–∞–ø–∏—à–∏ <b>–Ω–µ—Ç</b>.")
    await state.set_state(DocGenState.waiting_for_special_terms)


# –û–±—Ä–∞–±–æ—Ç–∫–∞ —É—Ç–æ—á–Ω–µ–Ω–∏–π
@dp.message(DocGenState.waiting_for_special_terms)
async def handle_additions(message: Message, state: FSMContext):
    data = await state.get_data()
    base_text = data.get("document_text", "")

    if message.text.strip().lower() == "–Ω–µ—Ç":
        await message.answer("‚úÖ –î–æ–∫—É–º–µ–Ω—Ç –∑–∞–≤–µ—Ä—à—ë–Ω. –£–¥–∞—á–∏!")
        await state.clear()
        return

    prompt = (
        "–í–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç. –î–æ–±–∞–≤—å –≤ –Ω–µ–≥–æ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Å–ª–µ–¥—É—é—â–∏–µ –æ—Å–æ–±—ã–µ —É—Å–ª–æ–≤–∏—è, —Å–æ—Ö—Ä–∞–Ω–∏–≤ —Å—Ç–∏–ª—å –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É:\n\n"
        f"–£—Å–ª–æ–≤–∏—è: {message.text}\n\n–î–æ–∫—É–º–µ–Ω—Ç:\n{base_text}"
    )
    await message.answer("üîß –í–Ω–æ—à—É –∏–∑–º–µ–Ω–µ–Ω–∏—è...")

    updated_doc = await generate_gpt_response(
        "–¢—ã —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π —Ä–µ–¥–∞–∫—Ç–æ—Ä. –í–Ω–æ—Å–∏ —Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø—Ä–∞–≤–∫–∏, —Å–æ—Ö—Ä–∞–Ω—è—è —Å—Ç–∏–ª—å.",
        prompt
    )

    final_path = save_docx(updated_doc, f"final_{message.from_user.id}.docx")
    await message.answer("üìÑ –î–æ–∫—É–º–µ–Ω—Ç —Å —É—á—ë—Ç–æ–º —É—Å–ª–æ–≤–∏–π:")
    await message.answer_document(FSInputFile(final_path))
    await message.answer("‚úÖ –ì–æ—Ç–æ–≤–æ!")
    await state.clear()


# –ó–∞–ø—É—Å–∫
if __name__ == "__main__":
    asyncio.run(dp.start_polling(bot))
